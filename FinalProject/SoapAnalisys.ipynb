{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name\n",
    "This project notebook intends to predict, Given a dataset of clients, which is more likely to accept and invite and buy\n",
    "the companies product.\n",
    "We will demonstrate and explain the analysis and explain our method of work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (from scikit-learn) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\ofeks\\OneDrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (from xgboost) (1.24.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\ofeks\\OneDrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ofeks\\onedrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\ofeks\\OneDrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install xgboost\n",
    "%pip install tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.utils import class_weight\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step\n",
    "In order to use the 'reviews' data sets in our complete prediction model. We will need to predict the raiting of each review\n",
    "the same way we did in the bonus assignment. The predicted rating will help us in taking advantage of the review data.\n",
    "- The model will be built the same way as it was built in the bonus assignment.\n",
    "- The data used will be the data given in the bonus assignment.\n",
    "- The trained model will be used to predict the rating in the reviews_rollout.csv and reviews_training.csv\n",
    "- The act of training the model on data X and predicting on data was is valid becuase the populations are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_bonus_ass_model():\n",
    "    \"\"\"\n",
    "        The function repeats the training process of the model in the\n",
    "        Bonus assignment. Returned values are the trained model and the selected values.\n",
    "\n",
    "        Features selection is done by '''SelectPercentile'''.\n",
    "        Model used is XGBoost.\n",
    "        Test is 20% of total data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"../BonusAssignment/text_training.csv\", usecols=list(range(1,2002)))\n",
    "\n",
    "    # separate the features and target variable\n",
    "    features = df.iloc[:, 1:-1] # all columns except the last one (rating)\n",
    "    labels = df.iloc[:, -1] # last column (rating)\n",
    "\n",
    "    selector = SelectPercentile(percentile=10)\n",
    "    x = selector.fit_transform(features, labels)\n",
    "    selected_features = selector.get_feature_names_out()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "    xgb_bonus_clf = xgb.XGBClassifier(max_depth=4, seed=2)\n",
    "    xgb_bonus_clf.fit(x_train, y_train)\n",
    "\n",
    "    return xgb_bonus_clf, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonus_ass_rating_prediction(table_path, trained_model, select_features):\n",
    "    \"\"\"\n",
    "        The function Receives the path to one of the foloowing tables: 'reviews_rollout.csv'\n",
    "        or 'reviews_training.csv' and returns the predicted values in dataframe along with the\n",
    "        respected ids.\n",
    "\n",
    "        Assumptions:\n",
    "        1. Both tables contain an id column\n",
    "        2. Rating Column does not appear in any table\n",
    "        3. model was Trained on the same tryp of population\n",
    "    \"\"\"    \n",
    "    df = pd.read_csv(table_path)\n",
    "    selected = df[select_features]\n",
    "    y_pred = trained_model.predict(selected)\n",
    "\n",
    "    return pd.concat([df[\"ID\"], pd.Series(y_pred, name='Rating')], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Predict - Bonus model\n",
    "The following section uses the functions above to predict the raiting column in the given reviews tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ofeks\\OneDrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [1208 1527] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\ofeks\\OneDrive\\תואר_שני\\שנה ב\\סמסטר א\\נושאים מתקדמים במדעי הנתונים למנהל עסקים\\temp_code\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "trained_model, selected_features = train_bonus_ass_model()\n",
    "y_pred_rev_training =   bonus_ass_rating_prediction(\"Documents/reviews_training.csv\", trained_model, selected_features)\n",
    "y_pred_rev_rollout =    bonus_ass_rating_prediction(\"Documents/reviews_rollout.csv\", trained_model, selected_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge tables\n",
    "- ffp_rollout_X\n",
    "- ffp_train\n",
    "\n",
    "The merge process has one critical issue: Not all ID's in the ffp table, exist in the reviews table, That is when when performing an ```outer join```, the combined data will have ```Nan``` values in the ```Rating``` column.\n",
    "We will deal with this issue in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffp_train = pd.read_csv(\"Documents/ffp_train.csv\")\n",
    "merged_ffp_train = pd.merge(left=df_ffp_train, right=y_pred_rev_training,how=\"outer\", on=\"ID\")\n",
    "\n",
    "df_ffp_rollout = pd.read_csv(\"Documents/ffp_rollout_X.csv\")\n",
    "merged_ffp_rollout = pd.merge(left=df_ffp_rollout, right=y_pred_rev_rollout,how=\"outer\", on=\"ID\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two\n",
    "### Choosing a model\n",
    "\n",
    "In order to predict the ```Buyer flag``` of the ffp table, we will use the merged tables.\n",
    "The problem: Some rows contain the rating value and some dont. To solve this, we will build model that is made out of two different models. One will work on the fpp table and one will work on the merged table. Predicted value will be chosen from one of the two results\n",
    "\n",
    "### Model 1 - Table containing both rating and ffp data\n",
    "Clear all ```Nan``` values from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide the data according to the rating values.\n",
    "# model1 will use df_ffp_data (data with no rating prediction)\n",
    "# model2 will use df_combined_data (data with rating prediction)\n",
    "\n",
    "#df_model1_train_no_rating = merged_ffp_train[merged_ffp_train[\"Rating\"].isna()].drop(\"Rating\", axis=1)\n",
    "df_model2_train_both = merged_ffp_train[~merged_ffp_train[\"Rating\"].isna()]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different models\n",
    "We will try two algorithms and two feature selection methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip ID and label\n",
    "features = df_model2_train_both.drop([\"BUYER_FLAG\",\"ID\"], axis=1)\n",
    "# Extract the label column\n",
    "label = df_model2_train_both[\"BUYER_FLAG\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature selection methods\n",
    "- One uses a correlation matrix to pick the most corralated features with the label.\n",
    "- The second uses the function ```SelectPercentile```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_by_corr(data, treshold):\n",
    "    mat = data.corr().drop(\"BUYER_FLAG\", axis=0)\n",
    "    mat = mat[abs(mat[\"BUYER_FLAG\"]) > treshold]\n",
    "    return list(mat.index)\n",
    "    #REMOVE THE BUYER FLAG\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "def select_features_by_SelecPer(features, lable, p):\n",
    "    selector = SelectPercentile(percentile=p)\n",
    "    selector.fit_transform(features, label)\n",
    "    return selector.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studying the label properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum corrlation value with 'BUYER_FLAG': 0.0031826178888089756\n",
      "Maximum corrlation value with 'BUYER_FLAG': 0.560140516762669\n"
     ]
    }
   ],
   "source": [
    "data = df_model2_train_both.iloc[:,1:] # Get rid of ID col\n",
    "\n",
    "mat = data.corr().drop(\"BUYER_FLAG\", axis=0)\n",
    "mat[\"BUYER_FLAG\"] = abs(mat[\"BUYER_FLAG\"])\n",
    "print(f\"Minimum corrlation value with 'BUYER_FLAG': {mat.describe()['BUYER_FLAG'].loc['min']}\")\n",
    "print(f\"Maximum corrlation value with 'BUYER_FLAG': {mat.describe()['BUYER_FLAG'].loc['max']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying XGBoost with Selection by corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5570/5570 [00:21<00:00, 256.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The best XGBoost model...\n",
      "Has a treshold of 0.0261\n",
      "Uses 10 features\n",
      "Has a model depth of 2\n",
      "and an F1 score of 0.6382978723404256\n",
      "Features selected: ['STATUS_PANTINUM', 'STATUS_GOLD', 'STATUS_SILVER', 'FARE_L_Y1', 'FARE_L_Y4', 'FARE_L_Y5', 'POINTS_L_Y4', 'POINTS_L_Y5', 'COUPON_FLAG', 'Rating']\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "best_score = 0                         # Hold the F1 score of the best model\n",
    "score = 0                              # Score of the current model\n",
    "last_count = -1                        # flag for preventing reapetition\n",
    "best_features = []\n",
    "best_model_xgb_corr = \"\"\n",
    "st = \"\"                                # Result string\n",
    "\n",
    "for t in tqdm(range(30, 5600, 1)): # 0.03 Treshold includes all 22 features\n",
    " \n",
    "    # Treshold is iterated from 0.003 to 0.56 increasing by 0.0001\n",
    "    treshold = t / 10000\n",
    "    selected_features = select_features_by_corr(data, treshold)\n",
    "\n",
    "    # Break condition\n",
    "    if len(selected_features) == last_count:\n",
    "        continue\n",
    "    else:\n",
    "        last_count = len(selected_features)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features[selected_features], label, test_size=0.2, random_state=1)\n",
    "    for d in range(1, 10, 1):\n",
    "        \n",
    "        # Train XGBoost model\n",
    "        classes_weights = class_weight.compute_sample_weight(\n",
    "            class_weight='balanced',\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "        xgbclf = xgb.XGBClassifier(max_depth=d, seed=2)\n",
    "        xgbclf.fit(x_train, y_train, sample_weight=classes_weights)\n",
    "        y_pred = xgbclf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        # print(f\"Current run:\\nThresh: {treshold}\\nVariables: {len(selected_features)}\\n d: {d}\\nF1: {score}\")\n",
    "\n",
    "        # Hold the best score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_features = selected_features\n",
    "            best_model_xgb_corr = xgbclf\n",
    "            st = f\"The best XGBoost model...\\nHas a treshold of {treshold}\\nUses {len(selected_features)} features\\nHas a model depth of {d}\\nand an F1 score of {best_score}\"\n",
    "            st += f\"\\nFeatures selected: {best_features}\"\n",
    "print(40*\"~\", st, 40*\"~\", sep=\"\\n\", end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Random Forest with selection by corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5570 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "best_score = 0                         # Hold the F1 score of the best model\n",
    "score = 0                              # Score of the current model\n",
    "last_count = -1                        # flag for preventing reapetition\n",
    "best_features = []\n",
    "best_model_rf_corr = \"\"\n",
    "st = \"\"                                # Result string\n",
    "\n",
    "for t in tqdm(range(30, 5600, 1)): # 0.03 Treshold includes all 22 features\n",
    " \n",
    "    # Treshold is iterated from 0.003 to 0.56 increasing by 0.0001\n",
    "    treshold = t / 10000\n",
    "    selected_features = select_features_by_corr(data, treshold)\n",
    "\n",
    "    # Break condition\n",
    "    if len(selected_features) == last_count:\n",
    "        continue\n",
    "    else:\n",
    "        last_count = len(selected_features)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features[selected_features], label, test_size=0.2, random_state=1)\n",
    "    for n_e in range(25, 200, 1):\n",
    "        # Train XGBoost model\n",
    "        rf = RandomForestClassifier(n_estimators=n_e, class_weight='balanced')\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        # print(f\"Current run:\\nThresh: {treshold}\\nVariables: {len(selected_features)}\\n d: {d}\\nF1: {score}\")\n",
    "\n",
    "        # Hold the best score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_features = selected_features\n",
    "            best_model_rf_corr = rf\n",
    "            st = f\"The best Random Forest model...\\nHas a treshold of {treshold}\\nUses {len(selected_features)} features\\nHas {n_e} estimators\\nand an F1 score of {best_score}\"\n",
    "            st += f\"\\nFeatures selected: {best_features}\"\n",
    "\n",
    "\n",
    "print(40*\"~\", st, 40*\"~\", sep=\"\\n\", end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now repeat the algorithmes above, using the select percentile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The best XGBoost model...\n",
      "Has a percentile of 43\n",
      "Uses 10 features\n",
      "Has a model depth of 2\n",
      "and an F1 score of 0.6382978723404256\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "best_score = 0                         # Hold the F1 score of the best model\n",
    "score = 0                              # Score of the current model\n",
    "last_count = -1                        # flag for preventing reapetition\n",
    "best_features_xgb_per = []\n",
    "best_model_xgb_per = \"\"\n",
    "st = \"\"                                # Result string\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)): \n",
    " \n",
    "    selected_features = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    # Break condition\n",
    "    if len(selected_features) == last_count:\n",
    "        continue\n",
    "    else:\n",
    "        last_count = len(selected_features)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features[selected_features], label, test_size=0.2, random_state=1)\n",
    "    for d in range(1, 10, 1):\n",
    "        # Train XGBoost model\n",
    "        classes_weights = class_weight.compute_sample_weight(\n",
    "            class_weight='balanced',\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "        xgbclf = xgb.XGBClassifier(max_depth=d, seed=2)\n",
    "        xgbclf.fit(x_train, y_train, sample_weight=classes_weights)\n",
    "        y_pred = xgbclf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        # print(f\"Current run:\\nThresh: {treshold}\\nVariables: {len(selected_features)}\\n d: {d}\\nF1: {score}\")\n",
    "\n",
    "        # Hold the best score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_features_xgb_per = selected_features\n",
    "            best_model_xgb_per = xgbclf\n",
    "            st = f\"The best XGBoost model...\\nHas a percentile of {p}\\nUses {len(selected_features)} features\\nHas a model depth of {d}\\nand an F1 score of {best_score}\"\n",
    "            \n",
    "print(40*\"~\", st, 40*\"~\", sep=\"\\n\", end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the RandomForest with the selectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [13:21<00:00,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The best Random Forest model...\n",
      "Has a percentile of 15\n",
      "Uses 4 features\n",
      "Has 1 Estimators\n",
      "and an F1 score of 0.6326530612244898\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "best_score = 0                         # Hold the F1 score of the best model\n",
    "score = 0                              # Score of the current model\n",
    "last_count = -1                        # flag for preventing reapetition\n",
    "best_features_rf_per = []\n",
    "best_model_rf_per = \"\"\n",
    "st = \"\"                                # Result string\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)): \n",
    " \n",
    "    selected_features = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    # Break condition\n",
    "    if len(selected_features) == last_count:\n",
    "        continue\n",
    "    else:\n",
    "        last_count = len(selected_features)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features[selected_features], label, test_size=0.2, random_state=1)\n",
    "    for n_e in range(1, 200, 1):\n",
    "        # Train XGBoost model\n",
    "        rf = RandomForestClassifier(n_estimators=n_e, class_weight='balanced')\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        # print(f\"Current run:\\nThresh: {treshold}\\nVariables: {len(selected_features)}\\n d: {d}\\nF1: {score}\")\n",
    "\n",
    "        # Hold the best score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_features_rf_per = selected_features\n",
    "            best_model_rf_per = rf\n",
    "            st = f\"The best Random Forest model...\\nHas a percentile of {p}\\nUses {len(selected_features)} features\\nHas {n_e} Estimators\\nand an F1 score of {best_score}\"\n",
    "            \n",
    "print(40*\"~\", st, 40*\"~\", sep=\"\\n\", end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Table containing ffp data only\n",
    "\n",
    "Need to rerun models...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CUSTOMER_GRADE</th>\n",
       "      <th>STATUS_PANTINUM</th>\n",
       "      <th>STATUS_GOLD</th>\n",
       "      <th>STATUS_SILVER</th>\n",
       "      <th>NUM_DEAL</th>\n",
       "      <th>LAST_DEAL</th>\n",
       "      <th>ADVANCE_PURCHASE</th>\n",
       "      <th>FARE_L_Y1</th>\n",
       "      <th>FARE_L_Y2</th>\n",
       "      <th>...</th>\n",
       "      <th>POINTS_L_Y1</th>\n",
       "      <th>POINTS_L_Y2</th>\n",
       "      <th>POINTS_L_Y3</th>\n",
       "      <th>POINTS_L_Y4</th>\n",
       "      <th>POINTS_L_Y5</th>\n",
       "      <th>COUPON_FLAG</th>\n",
       "      <th>CANCEL_FLAG</th>\n",
       "      <th>CREDIT_FLAG</th>\n",
       "      <th>RELATED_FLAG</th>\n",
       "      <th>BUYER_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11.545711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>24</td>\n",
       "      <td>82.7</td>\n",
       "      <td>92.7</td>\n",
       "      <td>...</td>\n",
       "      <td>71.3</td>\n",
       "      <td>60.7</td>\n",
       "      <td>98.1</td>\n",
       "      <td>81.6</td>\n",
       "      <td>78.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.493459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26.7</td>\n",
       "      <td>27</td>\n",
       "      <td>120.7</td>\n",
       "      <td>112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.3</td>\n",
       "      <td>112.5</td>\n",
       "      <td>104.6</td>\n",
       "      <td>110.9</td>\n",
       "      <td>137.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.882457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>9</td>\n",
       "      <td>97.3</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>107.7</td>\n",
       "      <td>120.7</td>\n",
       "      <td>62.5</td>\n",
       "      <td>63.9</td>\n",
       "      <td>92.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9.511699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>61.3</td>\n",
       "      <td>24</td>\n",
       "      <td>123.3</td>\n",
       "      <td>130.7</td>\n",
       "      <td>...</td>\n",
       "      <td>129.5</td>\n",
       "      <td>132.1</td>\n",
       "      <td>135.1</td>\n",
       "      <td>104.1</td>\n",
       "      <td>118.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>14.798792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37.3</td>\n",
       "      <td>20</td>\n",
       "      <td>136.0</td>\n",
       "      <td>135.3</td>\n",
       "      <td>...</td>\n",
       "      <td>145.7</td>\n",
       "      <td>124.5</td>\n",
       "      <td>122.7</td>\n",
       "      <td>140.1</td>\n",
       "      <td>130.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29996</td>\n",
       "      <td>8.993560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25</td>\n",
       "      <td>98.7</td>\n",
       "      <td>92.7</td>\n",
       "      <td>...</td>\n",
       "      <td>57.2</td>\n",
       "      <td>89.1</td>\n",
       "      <td>83.5</td>\n",
       "      <td>56.1</td>\n",
       "      <td>79.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29997</td>\n",
       "      <td>9.809759</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>117.3</td>\n",
       "      <td>20</td>\n",
       "      <td>228.0</td>\n",
       "      <td>233.3</td>\n",
       "      <td>...</td>\n",
       "      <td>178.9</td>\n",
       "      <td>215.5</td>\n",
       "      <td>214.1</td>\n",
       "      <td>216.7</td>\n",
       "      <td>232.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29998</td>\n",
       "      <td>11.226843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21</td>\n",
       "      <td>84.7</td>\n",
       "      <td>87.3</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>83.4</td>\n",
       "      <td>81.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>90.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29999</td>\n",
       "      <td>12.926248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42.7</td>\n",
       "      <td>20</td>\n",
       "      <td>121.3</td>\n",
       "      <td>126.7</td>\n",
       "      <td>...</td>\n",
       "      <td>98.9</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>158.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>30000</td>\n",
       "      <td>14.157538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>29.3</td>\n",
       "      <td>22</td>\n",
       "      <td>167.3</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>150.3</td>\n",
       "      <td>127.7</td>\n",
       "      <td>126.1</td>\n",
       "      <td>135.1</td>\n",
       "      <td>113.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  CUSTOMER_GRADE  STATUS_PANTINUM  STATUS_GOLD  STATUS_SILVER  \\\n",
       "0          1       11.545711                0            0              0   \n",
       "1          2        9.493459                0            0              0   \n",
       "2          3        3.882457                0            0              0   \n",
       "3          4        9.511699                0            0              0   \n",
       "4          5       14.798792                0            0              0   \n",
       "...      ...             ...              ...          ...            ...   \n",
       "29995  29996        8.993560                0            0              0   \n",
       "29996  29997        9.809759                0            1              0   \n",
       "29997  29998       11.226843                0            0              0   \n",
       "29998  29999       12.926248                0            0              0   \n",
       "29999  30000       14.157538                0            0              0   \n",
       "\n",
       "       NUM_DEAL  LAST_DEAL  ADVANCE_PURCHASE  FARE_L_Y1  FARE_L_Y2  ...  \\\n",
       "0             3       29.3                24       82.7       92.7  ...   \n",
       "1             5       26.7                27      120.7      112.0  ...   \n",
       "2             4       26.7                 9       97.3       92.0  ...   \n",
       "3             2       61.3                24      123.3      130.7  ...   \n",
       "4             4       37.3                20      136.0      135.3  ...   \n",
       "...         ...        ...               ...        ...        ...  ...   \n",
       "29995         6       16.0                25       98.7       92.7  ...   \n",
       "29996         2      117.3                20      228.0      233.3  ...   \n",
       "29997         4       24.0                21       84.7       87.3  ...   \n",
       "29998         3       42.7                20      121.3      126.7  ...   \n",
       "29999         6       29.3                22      167.3      166.0  ...   \n",
       "\n",
       "       POINTS_L_Y1  POINTS_L_Y2  POINTS_L_Y3  POINTS_L_Y4  POINTS_L_Y5  \\\n",
       "0             71.3         60.7         98.1         81.6         78.6   \n",
       "1            126.3        112.5        104.6        110.9        137.3   \n",
       "2            107.7        120.7         62.5         63.9         92.9   \n",
       "3            129.5        132.1        135.1        104.1        118.2   \n",
       "4            145.7        124.5        122.7        140.1        130.9   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29995         57.2         89.1         83.5         56.1         79.8   \n",
       "29996        178.9        215.5        214.1        216.7        232.6   \n",
       "29997         53.0         83.4         81.3         73.9         90.6   \n",
       "29998         98.9         80.0         89.0        121.5        158.5   \n",
       "29999        150.3        127.7        126.1        135.1        113.7   \n",
       "\n",
       "       COUPON_FLAG  CANCEL_FLAG  CREDIT_FLAG  RELATED_FLAG  BUYER_FLAG  \n",
       "0                0            0            0             0           0  \n",
       "1                0            0            1             0           0  \n",
       "2                0            0            0             0           0  \n",
       "3                0            0            0             0           0  \n",
       "4                0            0            0             0           0  \n",
       "...            ...          ...          ...           ...         ...  \n",
       "29995            0            0            0             0           0  \n",
       "29996            0            0            0             0           0  \n",
       "29997            0            0            0             0           0  \n",
       "29998            0            0            0             0           0  \n",
       "29999            1            0            0             0           1  \n",
       "\n",
       "[30000 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ffp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_model1_train_no_rating' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m features \u001b[39m=\u001b[39m df_model1_train_no_rating\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m label \u001b[39m=\u001b[39m df_model1_train_no_rating[\u001b[39m\"\u001b[39m\u001b[39mBUYER_FLAG\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(features, label, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_model1_train_no_rating' is not defined"
     ]
    }
   ],
   "source": [
    "features = df_ffp_train.drop([\"ID\", \"BUYER_FLAG\"], axis=1)\n",
    "label = df_ffp_train[\"BUYER_FLAG\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_xgboost(features, label):\n",
    "    \n",
    "    parameters = {'score': 0,\n",
    "                  'features': [],\n",
    "                  'model': [],\n",
    "                  'depth': -1\n",
    "                  }        \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=1)\n",
    "\n",
    "    for d in range(1, 10, 1):\n",
    "        classes_weights = class_weight.compute_sample_weight(\n",
    "            class_weight='balanced',\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "        xgbclf = xgb.XGBClassifier(max_depth=d, seed=2)\n",
    "        xgbclf.fit(x_train, y_train, sample_weight=classes_weights)\n",
    "        y_pred = xgbclf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "                \n",
    "        if score > parameters['score']:\n",
    "            parameters['score'] = score\n",
    "            parameters['features'] = selected_features\n",
    "            parameters['model'] = xgbclf\n",
    "            parameters['depth'] = d\n",
    "            #st = f\"The best XGBoost model...\\nHas a treshold of {treshold}\\nUses {len(selected_features)} features\\nHas a model depth of {d}\\nand an F1 score of {best_score}\"\n",
    "            #st += f\"\\nFeatures selected: {best_features}\"\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_rf(features, label):\n",
    "\n",
    "    parameters = {'score': 0,\n",
    "                  'features': [],\n",
    "                  'model': [],\n",
    "                  'n_estimators': -1\n",
    "                } \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=1)\n",
    "    \n",
    "    for n_e in range(1, 200, 1):\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=n_e, class_weight='balanced')\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "\n",
    "        if score > parameters['score']:\n",
    "            parameters['score'] = score\n",
    "            parameters['features'] = selected_features\n",
    "            parameters['model'] = rf\n",
    "            parameters['n_estimators'] = n_e\n",
    "            \n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {}\n",
    "\n",
    "for i in tqdm(range(1, 500, 1)):\n",
    "    treshold = i / 1000\n",
    "    selected = select_features_by_corr(df_ffp_train,treshold)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_xgboost(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "\n",
    "params_xgb_corr = best_params\n",
    "params_xgb_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {}\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)):\n",
    "    selected = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_xgboost(selected, label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "\n",
    "params_xgb_per = best_params\n",
    "params_xgb_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {}\n",
    "\n",
    "for i in tqdm(range(1, 500, 1)):\n",
    "    treshold = i / 1000\n",
    "    selected = select_features_by_corr(df_ffp_train,treshold)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_rf(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "\n",
    "params_rf_corr = best_params\n",
    "params_rf_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {}\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)):\n",
    "    selected = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_rf(selected, label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "\n",
    "params_rf_per = best_params\n",
    "params_rf_per"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the \"Winning\" models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = ''\n",
    "model2 = ''\n",
    "\n",
    "recommandations = pd.DataFrame(columns=\"BUYER_FLAG\")\n",
    "\n",
    "def combined_model(row):\n",
    "    x = row.drop([\"BUYER_FLAG\"], axis=1)\n",
    "    if x[\"Rating\"].isna():\n",
    "        return model2.predict(x.drop([\"Rating\"], axis=1))\n",
    "    return model1.predict(x)\n",
    "\n",
    "recommandations[\"BUYER_FLAG\"] = pd.apply(data=merged_ffp_rollout, combined_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c6c368fee16ae7d9e5f6bc2ea9ce3a6d793cd0c63a6735b25b27ad16ffa3269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
