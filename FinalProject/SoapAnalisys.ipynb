{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name\n",
    "This project notebook intends to predict, Given a dataset of clients, which is more likely to accept and invite and buy\n",
    "the companies product.\n",
    "We will demonstrate and explain the analysis and explain our method of work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\ofeks\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ofeks\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ofeks\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ofeks\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ofeks\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\ofeks\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ofeks\\appdata\\roaming\\python\\python311\\site-packages (from xgboost) (1.23.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\ofeks\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install xgboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step\n",
    "In order to use the 'reviews' data sets in our complete prediction model. We will need to predict the raiting of each review\n",
    "the same way we did in the bonus assignment. The predicted rating will help us in taking advantage of the review data.\n",
    "- The model will be built the same way as it was built in the bonus assignment.\n",
    "- The data used will be the data given in the bonus assignment.\n",
    "- The trained model will be used to predict the rating in the reviews_rollout.csv and reviews_training.csv\n",
    "- The act of training the model on data X and predicting on data was is valid becuase the populations are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_bonus_ass_model():\n",
    "    \"\"\"\n",
    "        The function repeats the training process of the model in the\n",
    "        Bonus assignment. Returned values are the trained model and the selected values.\n",
    "\n",
    "        Features selection is done by '''SelectPercentile'''.\n",
    "        Model used is XGBoost.\n",
    "        Test is 20% of total data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"../BonusAssignment/text_training.csv\", usecols=list(range(1,2002)))\n",
    "\n",
    "    # separate the features and target variable\n",
    "    features = df.iloc[:, 1:-1] # all columns except the last one (rating)\n",
    "    labels = df.iloc[:, -1] # last column (rating)\n",
    "\n",
    "    selector = SelectPercentile(percentile=10)\n",
    "    x = selector.fit_transform(features, labels)\n",
    "    selected_features = selector.get_feature_names_out()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "    xgb_bonus_clf = xgb.XGBClassifier(max_depth=4, seed=2)\n",
    "    xgb_bonus_clf.fit(x_train, y_train)\n",
    "\n",
    "    return xgb_bonus_clf, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonus_ass_rating_prediction(table_path, trained_model, select_features):\n",
    "    \"\"\"\n",
    "        The function Receives the path to one of the foloowing tables: 'reviews_rollout.csv'\n",
    "        or 'reviews_training.csv' and returns the predicted values in dataframe along with the\n",
    "        respected ids.\n",
    "\n",
    "        Assumptions:\n",
    "        1. Both tables contain an id column\n",
    "        2. Rating Column does not appear in any table\n",
    "        3. model was Trained on the same tryp of population\n",
    "    \"\"\"    \n",
    "    df = pd.read_csv(table_path)\n",
    "    selected = df[select_features]\n",
    "    y_pred = trained_model.predict(selected)\n",
    "\n",
    "    return pd.concat([df[\"ID\"], pd.Series(y_pred, name='Rating')], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Predict - Bonus model\n",
    "The following section uses the functions above to predict the raiting column in the given reviews tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [1208 1527] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>29938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>29948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>29969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>29980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>29984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1861 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Rating\n",
       "0         2       0\n",
       "1        14       1\n",
       "2        18       0\n",
       "3        93       1\n",
       "4        95       0\n",
       "...     ...     ...\n",
       "1856  29938       0\n",
       "1857  29948       0\n",
       "1858  29969       1\n",
       "1859  29980       1\n",
       "1860  29984       0\n",
       "\n",
       "[1861 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model, selected_features = train_bonus_ass_model()\n",
    "y_pred_rev_training =   bonus_ass_rating_prediction(\"Documents/reviews_training.csv\", trained_model, selected_features)\n",
    "y_pred_rev_rollout =    bonus_ass_rating_prediction(\"Documents/reviews_rollout.csv\", trained_model, selected_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge tables\n",
    "- ffp_rollout_X\n",
    "- ffp_train\n",
    "\n",
    "The merge process has one critical issue: Not all ID's in the ffp table, exist in the reviews table, That is when when performing an ```outer join```, the combined data will have ```Nan``` values in the ```Rating``` column.\n",
    "We will deal with this issue in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffp_train = pd.read_csv(\"Documents/ffp_train.csv\")\n",
    "merged_ffp_train = pd.merge(left=df_ffp_train, right=y_pred_rev_training,how=\"outer\", on=\"ID\")\n",
    "\n",
    "df_ffp_rollout = pd.read_csv(\"Documents/ffp_rollout_X.csv\")\n",
    "merged_ffp_rollout = pd.merge(left=df_ffp_rollout, right=y_pred_rev_rollout,how=\"outer\", on=\"ID\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two\n",
    "### Choosing a model\n",
    "\n",
    "In order to predict the ```Buyer flag``` of the ffp table, we will use the merged tables.\n",
    "The problem: Some rows contain the rating value and some dont. To solve this, we will build model that is made out of two different models. One will work on the fpp table and one will work on the merged table. Predicted value will be chosen from one of the two results\n",
    "\n",
    "### Model 1 - Table containing both rating and ffp data\n",
    "Clear all ```Nan``` values from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide the data according to the rating values.\n",
    "# model1 will use df_ffp_data (data with no rating prediction)\n",
    "# model2 will use df_combined_data (data with rating prediction)\n",
    "\n",
    "#df_model1_train_no_rating = merged_ffp_train[merged_ffp_train[\"Rating\"].isna()].drop(\"Rating\", axis=1)\n",
    "df_model2_train_both = merged_ffp_train[~merged_ffp_train[\"Rating\"].isna()]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different models\n",
    "We will try two algorithms and two feature selection methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_GRADE</th>\n",
       "      <th>STATUS_PANTINUM</th>\n",
       "      <th>STATUS_GOLD</th>\n",
       "      <th>STATUS_SILVER</th>\n",
       "      <th>NUM_DEAL</th>\n",
       "      <th>LAST_DEAL</th>\n",
       "      <th>ADVANCE_PURCHASE</th>\n",
       "      <th>FARE_L_Y1</th>\n",
       "      <th>FARE_L_Y2</th>\n",
       "      <th>FARE_L_Y3</th>\n",
       "      <th>...</th>\n",
       "      <th>POINTS_L_Y1</th>\n",
       "      <th>POINTS_L_Y2</th>\n",
       "      <th>POINTS_L_Y3</th>\n",
       "      <th>POINTS_L_Y4</th>\n",
       "      <th>POINTS_L_Y5</th>\n",
       "      <th>COUPON_FLAG</th>\n",
       "      <th>CANCEL_FLAG</th>\n",
       "      <th>CREDIT_FLAG</th>\n",
       "      <th>RELATED_FLAG</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.493459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26.7</td>\n",
       "      <td>27</td>\n",
       "      <td>120.7</td>\n",
       "      <td>112.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.3</td>\n",
       "      <td>112.5</td>\n",
       "      <td>104.6</td>\n",
       "      <td>110.9</td>\n",
       "      <td>137.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12.200276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.7</td>\n",
       "      <td>21</td>\n",
       "      <td>124.0</td>\n",
       "      <td>120.7</td>\n",
       "      <td>116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.5</td>\n",
       "      <td>147.9</td>\n",
       "      <td>123.4</td>\n",
       "      <td>120.4</td>\n",
       "      <td>119.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.248704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28</td>\n",
       "      <td>143.3</td>\n",
       "      <td>145.3</td>\n",
       "      <td>139.3</td>\n",
       "      <td>...</td>\n",
       "      <td>125.5</td>\n",
       "      <td>167.3</td>\n",
       "      <td>163.3</td>\n",
       "      <td>169.4</td>\n",
       "      <td>152.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>13.308937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21.3</td>\n",
       "      <td>9</td>\n",
       "      <td>104.7</td>\n",
       "      <td>97.3</td>\n",
       "      <td>104.7</td>\n",
       "      <td>...</td>\n",
       "      <td>85.1</td>\n",
       "      <td>111.5</td>\n",
       "      <td>94.5</td>\n",
       "      <td>108.1</td>\n",
       "      <td>125.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>10.420929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.7</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.1</td>\n",
       "      <td>90.3</td>\n",
       "      <td>117.7</td>\n",
       "      <td>109.7</td>\n",
       "      <td>97.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29937</th>\n",
       "      <td>8.813226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>22</td>\n",
       "      <td>87.3</td>\n",
       "      <td>80.7</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.1</td>\n",
       "      <td>96.4</td>\n",
       "      <td>78.8</td>\n",
       "      <td>88.8</td>\n",
       "      <td>100.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29947</th>\n",
       "      <td>12.060344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14</td>\n",
       "      <td>95.3</td>\n",
       "      <td>100.7</td>\n",
       "      <td>87.3</td>\n",
       "      <td>...</td>\n",
       "      <td>64.9</td>\n",
       "      <td>106.4</td>\n",
       "      <td>87.6</td>\n",
       "      <td>139.9</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29968</th>\n",
       "      <td>9.308334</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>22</td>\n",
       "      <td>218.7</td>\n",
       "      <td>224.0</td>\n",
       "      <td>228.7</td>\n",
       "      <td>...</td>\n",
       "      <td>178.8</td>\n",
       "      <td>192.6</td>\n",
       "      <td>219.3</td>\n",
       "      <td>218.7</td>\n",
       "      <td>223.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29979</th>\n",
       "      <td>12.411760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>45.3</td>\n",
       "      <td>14</td>\n",
       "      <td>146.0</td>\n",
       "      <td>141.3</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>142.9</td>\n",
       "      <td>188.8</td>\n",
       "      <td>144.1</td>\n",
       "      <td>155.6</td>\n",
       "      <td>154.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29983</th>\n",
       "      <td>7.964462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>17</td>\n",
       "      <td>79.3</td>\n",
       "      <td>95.3</td>\n",
       "      <td>97.3</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.7</td>\n",
       "      <td>99.2</td>\n",
       "      <td>126.3</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1861 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUSTOMER_GRADE  STATUS_PANTINUM  STATUS_GOLD  STATUS_SILVER  NUM_DEAL  \\\n",
       "1            9.493459                0            0              0         5   \n",
       "13          12.200276                0            0              0         2   \n",
       "17           8.248704                0            0              1         6   \n",
       "92          13.308937                0            0              0         5   \n",
       "94          10.420929                0            0              0         6   \n",
       "...               ...              ...          ...            ...       ...   \n",
       "29937        8.813226                0            0              0         7   \n",
       "29947       12.060344                0            0              0         5   \n",
       "29968        9.308334                0            1              0         5   \n",
       "29979       12.411760                0            0              1         3   \n",
       "29983        7.964462                0            0              0         3   \n",
       "\n",
       "       LAST_DEAL  ADVANCE_PURCHASE  FARE_L_Y1  FARE_L_Y2  FARE_L_Y3  ...  \\\n",
       "1           26.7                27      120.7      112.0      118.0  ...   \n",
       "13          58.7                21      124.0      120.7      116.0  ...   \n",
       "17          24.0                28      143.3      145.3      139.3  ...   \n",
       "92          21.3                 9      104.7       97.3      104.7  ...   \n",
       "94          16.0                15       90.0       90.7       94.0  ...   \n",
       "...          ...               ...        ...        ...        ...  ...   \n",
       "29937       13.3                22       87.3       80.7       84.0  ...   \n",
       "29947       16.0                14       95.3      100.7       87.3  ...   \n",
       "29968       48.0                22      218.7      224.0      228.7  ...   \n",
       "29979       45.3                14      146.0      141.3      138.0  ...   \n",
       "29983       34.7                17       79.3       95.3       97.3  ...   \n",
       "\n",
       "       POINTS_L_Y1  POINTS_L_Y2  POINTS_L_Y3  POINTS_L_Y4  POINTS_L_Y5  \\\n",
       "1            126.3        112.5        104.6        110.9        137.3   \n",
       "13           115.5        147.9        123.4        120.4        119.5   \n",
       "17           125.5        167.3        163.3        169.4        152.3   \n",
       "92            85.1        111.5         94.5        108.1        125.2   \n",
       "94            72.1         90.3        117.7        109.7         97.2   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29937         98.1         96.4         78.8         88.8        100.9   \n",
       "29947         64.9        106.4         87.6        139.9         94.5   \n",
       "29968        178.8        192.6        219.3        218.7        223.8   \n",
       "29979        142.9        188.8        144.1        155.6        154.2   \n",
       "29983         66.0         79.7         99.2        126.3        103.5   \n",
       "\n",
       "       COUPON_FLAG  CANCEL_FLAG  CREDIT_FLAG  RELATED_FLAG  Rating  \n",
       "1                0            0            1             0     0.0  \n",
       "13               0            0            0             0     1.0  \n",
       "17               0            0            0             0     0.0  \n",
       "92               0            0            0             0     1.0  \n",
       "94               0            0            0             0     0.0  \n",
       "...            ...          ...          ...           ...     ...  \n",
       "29937            0            1            0             0     0.0  \n",
       "29947            0            0            0             0     0.0  \n",
       "29968            0            0            0             1     1.0  \n",
       "29979            0            0            0             0     1.0  \n",
       "29983            0            0            0             0     0.0  \n",
       "\n",
       "[1861 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip ID and label\n",
    "features = df_model2_train_both.drop([\"BUYER_FLAG\",\"ID\"], axis=1)\n",
    "# Extract the label column\n",
    "label = df_model2_train_both[\"BUYER_FLAG\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature selection methods\n",
    "- One uses a correlation matrix to pick the most corralated features with the label.\n",
    "- The second uses the function ```SelectPercentile```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_by_corr(data, treshold):\n",
    "    mat = data.corr().drop(\"BUYER_FLAG\", axis=0)\n",
    "    mat = mat[abs(mat[\"BUYER_FLAG\"]) > treshold]\n",
    "    return list(mat.index)\n",
    "    #REMOVE THE BUYER FLAG\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "def select_features_by_SelecPer(features, lable, p):\n",
    "    selector = SelectPercentile(percentile=p)\n",
    "    selector.fit_transform(features, label)\n",
    "    return selector.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studying the label properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum corrlation value with 'BUYER_FLAG': 0.0031826178888089756\n",
      "Maximum corrlation value with 'BUYER_FLAG': 0.560140516762669\n"
     ]
    }
   ],
   "source": [
    "data = df_model2_train_both.iloc[:,1:] # Get rid of ID col\n",
    "\n",
    "mat = data.corr().drop(\"BUYER_FLAG\", axis=0)\n",
    "mat[\"BUYER_FLAG\"] = abs(mat[\"BUYER_FLAG\"])\n",
    "print(f\"Minimum corrlation value with 'BUYER_FLAG': {mat.describe()['BUYER_FLAG'].loc['min']}\")\n",
    "print(f\"Maximum corrlation value with 'BUYER_FLAG': {mat.describe()['BUYER_FLAG'].loc['max']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying XGBoost with Selection by corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5570/5570 [01:31<00:00, 60.69it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The best XGBoost model...\n",
      "Has a treshold of 0.0438\n",
      "Uses 3 features\n",
      "Has a model depth of 1\n",
      "and an F1 score of 0.6294416243654822\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_score = 0                         # Hold the F1 score of the best model\n",
    "score = 0                              # Score of the current model\n",
    "last_count = -1                        # flag for preventing reapetition\n",
    "st = \"\"                                # Result string\n",
    "\n",
    "for t in tqdm(range(30, 5600, 1)): # 0.03 Treshold includes all 22 features\n",
    " \n",
    "    # Treshold is iterated from 0.003 to 0.56 increasing by 0.0001\n",
    "    treshold = t / 10000\n",
    "    selected_features = select_features_by_corr(data, treshold)\n",
    "\n",
    "    # Break condition\n",
    "    if len(selected_features) == last_count:\n",
    "        continue\n",
    "    else:\n",
    "        last_count = len(selected_features)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features[selected_features], label, test_size=0.2, random_state=1)\n",
    "    for d in range(1, 10, 1):\n",
    "        # Train XGBoost model\n",
    "        xgbclf = xgb.XGBClassifier(max_depth=d, seed=2)\n",
    "        xgbclf.fit(x_train, y_train)\n",
    "        y_pred = xgbclf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        # print(f\"Current run:\\nThresh: {treshold}\\nVariables: {len(selected_features)}\\n d: {d}\\nF1: {score}\")\n",
    "\n",
    "        # Hold the best score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            st = f\"The best XGBoost model...\\nHas a treshold of {treshold}\\nUses {len(selected_features)} features\\nHas a model depth of {d}\\nand an F1 score of {best_score}\"\n",
    "            \n",
    "print(40*\"~\", st, 40*\"~\", sep=\"\\n\", end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Random Forest with selection by corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5570 [00:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m n_e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m25\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m1\u001b[39m):\n\u001b[0;32m     24\u001b[0m     \u001b[39m# Train XGBoost model\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     rf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39mn_e, class_weight\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m     rf\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m     27\u001b[0m     y_pred \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[0;32m     28\u001b[0m     score \u001b[39m=\u001b[39m f1_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    463\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    465\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    466\u001b[0m ]\n\u001b[0;32m    468\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    475\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    476\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    477\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    478\u001b[0m )(\n\u001b[0;32m    479\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    480\u001b[0m         t,\n\u001b[0;32m    481\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    482\u001b[0m         X,\n\u001b[0;32m    483\u001b[0m         y,\n\u001b[0;32m    484\u001b[0m         sample_weight,\n\u001b[0;32m    485\u001b[0m         i,\n\u001b[0;32m    486\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    487\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    488\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    489\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    860\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \n\u001b[0;32m    862\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 889\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    890\u001b[0m         X,\n\u001b[0;32m    891\u001b[0m         y,\n\u001b[0;32m    892\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    893\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:224\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 224\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    225\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(y)\n\u001b[0;32m    227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:199\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_classification_targets\u001b[39m(y):\n\u001b[0;32m    188\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39m        Target values.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     y_type \u001b[39m=\u001b[39m type_of_target(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\n\u001b[0;32m    201\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    202\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultilabel-sequences\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    206\u001b[0m     ]:\n\u001b[0;32m    207\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown label type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:363\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[39m# Check multiclass\u001b[39;00m\n\u001b[0;32m    362\u001b[0m first_row \u001b[39m=\u001b[39m y[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(y) \u001b[39melse\u001b[39;00m y\u001b[39m.\u001b[39mgetrow(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdata\n\u001b[1;32m--> 363\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39;49munique_values(y)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m (y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(first_row) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    364\u001b[0m     \u001b[39m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    365\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[0;32m    366\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:84\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.unique_values\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique_values\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m numpy\u001b[39m.\u001b[39;49munique(x)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_score = 0                         # Hold the F1 score of the best model\n",
    "score = 0                              # Score of the current model\n",
    "last_count = -1                        # flag for preventing reapetition\n",
    "st = \"\"                                # Result string\n",
    "\n",
    "for t in tqdm(range(30, 5600, 1)): # 0.03 Treshold includes all 22 features\n",
    " \n",
    "    # Treshold is iterated from 0.003 to 0.56 increasing by 0.0001\n",
    "    treshold = t / 10000\n",
    "    selected_features = select_features_by_corr(data, treshold)\n",
    "\n",
    "    # Break condition\n",
    "    if len(selected_features) == last_count:\n",
    "        continue\n",
    "    else:\n",
    "        last_count = len(selected_features)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features[selected_features], label, test_size=0.2, random_state=1)\n",
    "    for n_e in range(25, 200, 1):\n",
    "        # Train XGBoost model\n",
    "        rf = RandomForestClassifier(n_estimators=n_e, class_weight='balanced')\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        # print(f\"Current run:\\nThresh: {treshold}\\nVariables: {len(selected_features)}\\n d: {d}\\nF1: {score}\")\n",
    "\n",
    "        # Hold the best score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            st = f\"The best Random Forest model...\\nHas a treshold of {treshold}\\nUses {len(selected_features)} features\\nHas {n_e} estimators\\nand an F1 score of {best_score}\"\n",
    "            \n",
    "print(40*\"~\", st, 40*\"~\", sep=\"\\n\", end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now repeat the algorithmes above, using the select percentile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:03<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The best XGBoost model...\n",
      "Has a percentile of 1\n",
      "Uses 1 features\n",
      "Has a model depth of 1\n",
      "and an F1 score of 0.6294416243654822\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_score = 0                         # Hold the F1 score of the best model\n",
    "score = 0                              # Score of the current model\n",
    "last_count = -1                        # flag for preventing reapetition\n",
    "st = \"\"                                # Result string\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)): \n",
    " \n",
    "    selected_features = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    # Break condition\n",
    "    if len(selected_features) == last_count:\n",
    "        continue\n",
    "    else:\n",
    "        last_count = len(selected_features)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features[selected_features], label, test_size=0.2, random_state=1)\n",
    "    for d in range(1, 10, 1):\n",
    "        # Train XGBoost model\n",
    "        xgbclf = xgb.XGBClassifier(max_depth=d, seed=2)\n",
    "        xgbclf.fit(x_train, y_train)\n",
    "        y_pred = xgbclf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        # print(f\"Current run:\\nThresh: {treshold}\\nVariables: {len(selected_features)}\\n d: {d}\\nF1: {score}\")\n",
    "\n",
    "        # Hold the best score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            st = f\"The best XGBoost model...\\nHas a percentile of {p}\\nUses {len(selected_features)} features\\nHas a model depth of {d}\\nand an F1 score of {best_score}\"\n",
    "            \n",
    "print(40*\"~\", st, 40*\"~\", sep=\"\\n\", end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the RandomForest with the selectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m n_e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m200\u001b[39m, \u001b[39m1\u001b[39m):\n\u001b[0;32m     22\u001b[0m     \u001b[39m# Train XGBoost model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     rf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39mn_e, )\n\u001b[1;32m---> 24\u001b[0m     rf\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m     25\u001b[0m     y_pred \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[0;32m     26\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39msum\u001b[39m(y_pred))\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    463\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    465\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    466\u001b[0m ]\n\u001b[0;32m    468\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    475\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    476\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    477\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    478\u001b[0m )(\n\u001b[0;32m    479\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    480\u001b[0m         t,\n\u001b[0;32m    481\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    482\u001b[0m         X,\n\u001b[0;32m    483\u001b[0m         y,\n\u001b[0;32m    484\u001b[0m         sample_weight,\n\u001b[0;32m    485\u001b[0m         i,\n\u001b[0;32m    486\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    487\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    488\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    489\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:172\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     curr_sample_weight \u001b[39m=\u001b[39m sample_weight\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m--> 172\u001b[0m indices \u001b[39m=\u001b[39m _generate_sample_indices(\n\u001b[0;32m    173\u001b[0m     tree\u001b[39m.\u001b[39;49mrandom_state, n_samples, n_samples_bootstrap\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    175\u001b[0m sample_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(indices, minlength\u001b[39m=\u001b[39mn_samples)\n\u001b[0;32m    176\u001b[0m curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m sample_counts\n",
      "File \u001b[1;32mc:\\Users\\ofeks\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:129\u001b[0m, in \u001b[0;36m_generate_sample_indices\u001b[1;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39mPrivate function used to _parallel_build_trees function.\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m random_instance \u001b[39m=\u001b[39m check_random_state(random_state)\n\u001b[1;32m--> 129\u001b[0m sample_indices \u001b[39m=\u001b[39m random_instance\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, n_samples, n_samples_bootstrap)\n\u001b[0;32m    131\u001b[0m \u001b[39mreturn\u001b[39;00m sample_indices\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "best_score = 0                         # Hold the F1 score of the best model\n",
    "score = 0                              # Score of the current model\n",
    "last_count = -1                        # flag for preventing reapetition\n",
    "st = \"\"                                # Result string\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)): \n",
    " \n",
    "    selected_features = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    # Break condition\n",
    "    if len(selected_features) == last_count:\n",
    "        continue\n",
    "    else:\n",
    "        last_count = len(selected_features)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features[selected_features], label, test_size=0.2, random_state=1)\n",
    "    for n_e in range(1, 200, 1):\n",
    "        # Train XGBoost model\n",
    "        rf = RandomForestClassifier(n_estimators=n_e, )\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        # print(f\"Current run:\\nThresh: {treshold}\\nVariables: {len(selected_features)}\\n d: {d}\\nF1: {score}\")\n",
    "\n",
    "        # Hold the best score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            st = f\"The best Random Forest model...\\nHas a percentile of {p}\\nUses {len(selected_features)} features\\nHas {n_e} Estimators\\nand an F1 score of {best_score}\"\n",
    "            \n",
    "print(40*\"~\", st, 40*\"~\", sep=\"\\n\", end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Table containing ffp data only\n",
    "\n",
    "Need to rerun models...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_GRADE</th>\n",
       "      <th>STATUS_PANTINUM</th>\n",
       "      <th>STATUS_GOLD</th>\n",
       "      <th>STATUS_SILVER</th>\n",
       "      <th>NUM_DEAL</th>\n",
       "      <th>LAST_DEAL</th>\n",
       "      <th>ADVANCE_PURCHASE</th>\n",
       "      <th>FARE_L_Y1</th>\n",
       "      <th>FARE_L_Y2</th>\n",
       "      <th>FARE_L_Y3</th>\n",
       "      <th>...</th>\n",
       "      <th>FARE_L_Y5</th>\n",
       "      <th>POINTS_L_Y1</th>\n",
       "      <th>POINTS_L_Y2</th>\n",
       "      <th>POINTS_L_Y3</th>\n",
       "      <th>POINTS_L_Y4</th>\n",
       "      <th>POINTS_L_Y5</th>\n",
       "      <th>COUPON_FLAG</th>\n",
       "      <th>CANCEL_FLAG</th>\n",
       "      <th>CREDIT_FLAG</th>\n",
       "      <th>RELATED_FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.545711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>24</td>\n",
       "      <td>82.7</td>\n",
       "      <td>92.7</td>\n",
       "      <td>97.3</td>\n",
       "      <td>...</td>\n",
       "      <td>76.7</td>\n",
       "      <td>71.3</td>\n",
       "      <td>60.7</td>\n",
       "      <td>98.1</td>\n",
       "      <td>81.6</td>\n",
       "      <td>78.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.882457</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>9</td>\n",
       "      <td>97.3</td>\n",
       "      <td>92.0</td>\n",
       "      <td>95.3</td>\n",
       "      <td>...</td>\n",
       "      <td>88.7</td>\n",
       "      <td>107.7</td>\n",
       "      <td>120.7</td>\n",
       "      <td>62.5</td>\n",
       "      <td>63.9</td>\n",
       "      <td>92.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.511699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>61.3</td>\n",
       "      <td>24</td>\n",
       "      <td>123.3</td>\n",
       "      <td>130.7</td>\n",
       "      <td>123.3</td>\n",
       "      <td>...</td>\n",
       "      <td>120.7</td>\n",
       "      <td>129.5</td>\n",
       "      <td>132.1</td>\n",
       "      <td>135.1</td>\n",
       "      <td>104.1</td>\n",
       "      <td>118.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.798792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37.3</td>\n",
       "      <td>20</td>\n",
       "      <td>136.0</td>\n",
       "      <td>135.3</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>134.7</td>\n",
       "      <td>145.7</td>\n",
       "      <td>124.5</td>\n",
       "      <td>122.7</td>\n",
       "      <td>140.1</td>\n",
       "      <td>130.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.762368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26.7</td>\n",
       "      <td>25</td>\n",
       "      <td>102.7</td>\n",
       "      <td>79.3</td>\n",
       "      <td>81.3</td>\n",
       "      <td>...</td>\n",
       "      <td>104.7</td>\n",
       "      <td>78.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>82.4</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>8.993560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25</td>\n",
       "      <td>98.7</td>\n",
       "      <td>92.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>...</td>\n",
       "      <td>88.7</td>\n",
       "      <td>57.2</td>\n",
       "      <td>89.1</td>\n",
       "      <td>83.5</td>\n",
       "      <td>56.1</td>\n",
       "      <td>79.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>9.809759</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>117.3</td>\n",
       "      <td>20</td>\n",
       "      <td>228.0</td>\n",
       "      <td>233.3</td>\n",
       "      <td>237.3</td>\n",
       "      <td>...</td>\n",
       "      <td>232.7</td>\n",
       "      <td>178.9</td>\n",
       "      <td>215.5</td>\n",
       "      <td>214.1</td>\n",
       "      <td>216.7</td>\n",
       "      <td>232.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>11.226843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21</td>\n",
       "      <td>84.7</td>\n",
       "      <td>87.3</td>\n",
       "      <td>92.7</td>\n",
       "      <td>...</td>\n",
       "      <td>88.7</td>\n",
       "      <td>53.0</td>\n",
       "      <td>83.4</td>\n",
       "      <td>81.3</td>\n",
       "      <td>73.9</td>\n",
       "      <td>90.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>12.926248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42.7</td>\n",
       "      <td>20</td>\n",
       "      <td>121.3</td>\n",
       "      <td>126.7</td>\n",
       "      <td>120.7</td>\n",
       "      <td>...</td>\n",
       "      <td>123.3</td>\n",
       "      <td>98.9</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>158.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>14.157538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>29.3</td>\n",
       "      <td>22</td>\n",
       "      <td>167.3</td>\n",
       "      <td>166.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>168.0</td>\n",
       "      <td>150.3</td>\n",
       "      <td>127.7</td>\n",
       "      <td>126.1</td>\n",
       "      <td>135.1</td>\n",
       "      <td>113.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28139 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUSTOMER_GRADE  STATUS_PANTINUM  STATUS_GOLD  STATUS_SILVER  NUM_DEAL  \\\n",
       "0           11.545711                0            0              0         3   \n",
       "2            3.882457                0            0              0         4   \n",
       "3            9.511699                0            0              0         2   \n",
       "4           14.798792                0            0              0         4   \n",
       "5           11.762368                0            0              0         4   \n",
       "...               ...              ...          ...            ...       ...   \n",
       "29995        8.993560                0            0              0         6   \n",
       "29996        9.809759                0            1              0         2   \n",
       "29997       11.226843                0            0              0         4   \n",
       "29998       12.926248                0            0              0         3   \n",
       "29999       14.157538                0            0              0         6   \n",
       "\n",
       "       LAST_DEAL  ADVANCE_PURCHASE  FARE_L_Y1  FARE_L_Y2  FARE_L_Y3  ...  \\\n",
       "0           29.3                24       82.7       92.7       97.3  ...   \n",
       "2           26.7                 9       97.3       92.0       95.3  ...   \n",
       "3           61.3                24      123.3      130.7      123.3  ...   \n",
       "4           37.3                20      136.0      135.3      144.0  ...   \n",
       "5           26.7                25      102.7       79.3       81.3  ...   \n",
       "...          ...               ...        ...        ...        ...  ...   \n",
       "29995       16.0                25       98.7       92.7       92.0  ...   \n",
       "29996      117.3                20      228.0      233.3      237.3  ...   \n",
       "29997       24.0                21       84.7       87.3       92.7  ...   \n",
       "29998       42.7                20      121.3      126.7      120.7  ...   \n",
       "29999       29.3                22      167.3      166.0      166.0  ...   \n",
       "\n",
       "       FARE_L_Y5  POINTS_L_Y1  POINTS_L_Y2  POINTS_L_Y3  POINTS_L_Y4  \\\n",
       "0           76.7         71.3         60.7         98.1         81.6   \n",
       "2           88.7        107.7        120.7         62.5         63.9   \n",
       "3          120.7        129.5        132.1        135.1        104.1   \n",
       "4          134.7        145.7        124.5        122.7        140.1   \n",
       "5          104.7         78.5        105.0         98.5         82.4   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "29995       88.7         57.2         89.1         83.5         56.1   \n",
       "29996      232.7        178.9        215.5        214.1        216.7   \n",
       "29997       88.7         53.0         83.4         81.3         73.9   \n",
       "29998      123.3         98.9         80.0         89.0        121.5   \n",
       "29999      168.0        150.3        127.7        126.1        135.1   \n",
       "\n",
       "       POINTS_L_Y5  COUPON_FLAG  CANCEL_FLAG  CREDIT_FLAG  RELATED_FLAG  \n",
       "0             78.6            0            0            0             0  \n",
       "2             92.9            0            0            0             0  \n",
       "3            118.2            0            0            0             0  \n",
       "4            130.9            0            0            0             0  \n",
       "5            106.0            0            0            0             0  \n",
       "...            ...          ...          ...          ...           ...  \n",
       "29995         79.8            0            0            0             0  \n",
       "29996        232.6            0            0            0             0  \n",
       "29997         90.6            0            0            0             0  \n",
       "29998        158.5            0            0            0             0  \n",
       "29999        113.7            1            0            0             0  \n",
       "\n",
       "[28139 rows x 21 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_model1_train_no_rating.iloc[:,1:-1]\n",
    "label = df_model1_train_no_rating[\"BUYER_FLAG\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5edab282632443219e051e4ade2d1d5bbc671c781051bf1437897cbdfea0f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
