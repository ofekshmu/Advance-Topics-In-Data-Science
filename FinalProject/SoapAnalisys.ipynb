{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name\n",
    "This project notebook intends to predict, Given a dataset of clients, which is more likely to accept and invite and buy\n",
    "the companies product.\n",
    "We will demonstrate and explain the analysis and explain our method of work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.24.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\coffe\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n",
    "%pip install xgboost\n",
    "%pip install tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.utils import class_weight\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Step\n",
    "In order to use the 'reviews' data sets in our complete prediction model. We will need to predict the raiting of each review\n",
    "the same way we did in the bonus assignment. The predicted rating will help us in taking advantage of the review data.\n",
    "- The model will be built the same way as it was built in the bonus assignment.\n",
    "- The data used will be the data given in the bonus assignment.\n",
    "- The trained model will be used to predict the rating in the reviews_rollout.csv and reviews_training.csv\n",
    "- The act of training the model on data X and predicting on data was is valid becuase the populations are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bonus_ass_model():\n",
    "    \"\"\"\n",
    "        The function repeats the training process of the model in the\n",
    "        Bonus assignment. Returned values are the trained model and the selected values.\n",
    "\n",
    "        Features selection is done by '''SelectPercentile'''.\n",
    "        Model used is XGBoost.\n",
    "        Test is 20% of total data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"../BonusAssignment/text_training.csv\", usecols=list(range(1,2002)))\n",
    "\n",
    "    # separate the features and target variable\n",
    "    features = df.iloc[:, 1:-1] # all columns except the last one (rating)\n",
    "    labels = df.iloc[:, -1] # last column (rating)\n",
    "\n",
    "    selector = SelectPercentile(percentile=10)\n",
    "    x = selector.fit_transform(features, labels)\n",
    "    selected_features = selector.get_feature_names_out()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "    xgb_bonus_clf = xgb.XGBClassifier(max_depth=4, seed=2)\n",
    "    xgb_bonus_clf.fit(x_train, y_train)\n",
    "\n",
    "    return xgb_bonus_clf, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonus_ass_rating_prediction(table_path, trained_model, select_features):\n",
    "    \"\"\"\n",
    "        The function Receives the path to one of the foloowing tables: 'reviews_rollout.csv'\n",
    "        or 'reviews_training.csv' and returns the predicted values in dataframe along with the\n",
    "        respected ids.\n",
    "\n",
    "        Assumptions:\n",
    "        1. Both tables contain an id column\n",
    "        2. Rating Column does not appear in any table\n",
    "        3. model was Trained on the same tryp of population\n",
    "    \"\"\"    \n",
    "    df = pd.read_csv(table_path)\n",
    "    selected = df[select_features]\n",
    "    y_pred = trained_model.predict(selected)\n",
    "\n",
    "    return pd.concat([df[\"ID\"], pd.Series(y_pred, name='Rating')], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Predict - Bonus model\n",
    "The following section uses the functions above to predict the raiting column in the given reviews tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Coffe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [1208 1527] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\Coffe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "trained_model, selected_features = train_bonus_ass_model()\n",
    "y_pred_rev_training =   bonus_ass_rating_prediction(\"Documents/reviews_training.csv\", trained_model, selected_features)\n",
    "y_pred_rev_rollout =    bonus_ass_rating_prediction(\"Documents/reviews_rollout.csv\", trained_model, selected_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge tables\n",
    "- ffp_rollout_X\n",
    "- ffp_train\n",
    "\n",
    "The merge process has one critical issue: Not all ID's in the ffp table, exist in the reviews table, That is when when performing an ```outer join```, the combined data will have ```Nan``` values in the ```Rating``` column.\n",
    "We will deal with this issue in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffp_train = pd.read_csv(\"Documents/ffp_train.csv\")\n",
    "merged_ffp_train = pd.merge(left=df_ffp_train, right=y_pred_rev_training,how=\"outer\", on=\"ID\")\n",
    "\n",
    "df_ffp_rollout = pd.read_csv(\"Documents/ffp_rollout_X.csv\")\n",
    "merged_ffp_rollout = pd.merge(left=df_ffp_rollout, right=y_pred_rev_rollout,how=\"outer\", on=\"ID\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Two\n",
    "### Choosing a model\n",
    "\n",
    "In order to predict the ```Buyer flag``` of the ffp table, we will use the merged tables.\n",
    "The problem: Some rows contain the rating value and some dont. To solve this, we will build model that is made out of two different models. One will work on the fpp table and one will work on the merged table. Predicted value will be chosen from one of the two results\n",
    "\n",
    "### Model 1 - Table containing both rating and ffp data\n",
    "Clear all ```Nan``` values from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide the data according to the rating values.\n",
    "# model1 will use df_ffp_data (data with no rating prediction)\n",
    "# model2 will use df_combined_data (data with rating prediction)\n",
    "\n",
    "#df_model1_train_no_rating = merged_ffp_train[merged_ffp_train[\"Rating\"].isna()].drop(\"Rating\", axis=1)\n",
    "df_model2_train_both = merged_ffp_train[~merged_ffp_train[\"Rating\"].isna()]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing different models\n",
    "We will try two algorithms and two feature selection methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip ID and label\n",
    "features = df_model2_train_both.drop([\"BUYER_FLAG\",\"ID\"], axis=1)\n",
    "# Extract the label column\n",
    "label = df_model2_train_both[\"BUYER_FLAG\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature selection methods\n",
    "- One uses a correlation matrix to pick the most corralated features with the label.\n",
    "- The second uses the function ```SelectPercentile```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_by_corr(data, treshold):\n",
    "    mat = data.corr().drop([\"BUYER_FLAG\",\"ID\"], axis=0)\n",
    "    mat = mat[abs(mat[\"BUYER_FLAG\"]) > treshold]\n",
    "    return list(mat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "def select_features_by_SelecPer(features, lable, p):\n",
    "    selector = SelectPercentile(percentile=p)\n",
    "    selector.fit_transform(features, label)\n",
    "    return selector.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studying the label properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum corrlation value with 'BUYER_FLAG': 0.0031826178888089756\n",
      "Maximum corrlation value with 'BUYER_FLAG': 0.560140516762669\n"
     ]
    }
   ],
   "source": [
    "data = df_model2_train_both.iloc[:,1:] # Get rid of ID col\n",
    "\n",
    "mat = data.corr().drop(\"BUYER_FLAG\", axis=0)\n",
    "mat[\"BUYER_FLAG\"] = abs(mat[\"BUYER_FLAG\"])\n",
    "print(f\"Minimum corrlation value with 'BUYER_FLAG': {mat.describe()['BUYER_FLAG'].loc['min']}\")\n",
    "print(f\"Maximum corrlation value with 'BUYER_FLAG': {mat.describe()['BUYER_FLAG'].loc['max']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement function to wrap the full training and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_xgboost(features, label):\n",
    "    \n",
    "    parameters = {'score': 0,\n",
    "                  'features': [],\n",
    "                  'model': [],\n",
    "                  'depth': -1\n",
    "                  }        \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=1)\n",
    "\n",
    "    for d in range(1, 10, 1):\n",
    "        classes_weights = class_weight.compute_sample_weight(\n",
    "            class_weight='balanced',\n",
    "            y=y_train\n",
    "        )\n",
    "\n",
    "        xgbclf = xgb.XGBClassifier(max_depth=d, seed=2)\n",
    "        xgbclf.fit(x_train, y_train, sample_weight=classes_weights)\n",
    "        y_pred = xgbclf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "                \n",
    "        if score > parameters['score']:\n",
    "            parameters['score'] = score\n",
    "            parameters['model'] = xgbclf\n",
    "            parameters['depth'] = d\n",
    "            #st = f\"The best XGBoost model...\\nHas a treshold of {treshold}\\nUses {len(selected_features)} features\\nHas a model depth of {d}\\nand an F1 score of {best_score}\"\n",
    "            #st += f\"\\nFeatures selected: {best_features}\"\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_best_rf(features, label):\n",
    "\n",
    "    parameters = {'score': 0,\n",
    "                  'features': [],\n",
    "                  'model': [],\n",
    "                  'n_estimators': -1\n",
    "                } \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=1)\n",
    "    \n",
    "    for n_e in range(1, 200, 1):\n",
    "\n",
    "        rf = RandomForestClassifier(n_estimators=n_e, class_weight='balanced')\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_pred = rf.predict(x_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "\n",
    "        if score > parameters['score']:\n",
    "            parameters['score'] = score\n",
    "            parameters['model'] = rf\n",
    "            parameters['n_estimators'] = n_e\n",
    "            \n",
    "    return parameters    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets run the different models.. (names are not correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_output(params):\n",
    "    st = f\"{50*'~'}\\n\"\n",
    "    st += f\"The Model is {type(params['model'])}.\\n\"\n",
    "    st += f\"The number of features picked is {len(params['features'])}.\\n\"\n",
    "    \n",
    "    if \"depth\" in params.keys():\n",
    "        st += f\"The depth selected is {params['depth']}\\n\"\n",
    "\n",
    "    if \"n_estimator\" in params.keys():\n",
    "        st += f\"The number of estimators picked is {params['n_estimators']}\\n.\"\n",
    "\n",
    "    if \"percentile\" in params.keys():\n",
    "        st += f\"The percentile value is {params['percentile']}.\\n\"\n",
    "\n",
    "    if \"treshold\" in params.keys():\n",
    "        st += f\"The treshold chosen is {params['treshold']}.\\n\"\n",
    "    \n",
    "    st += f\"The F1 score is {params['score']}\\n.\"\n",
    "    st += f\"{50*'~'}\"\n",
    "    \n",
    "    print(st)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying XGBoost with Selection by corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CUSTOMER_GRADE</th>\n",
       "      <th>STATUS_PANTINUM</th>\n",
       "      <th>STATUS_GOLD</th>\n",
       "      <th>STATUS_SILVER</th>\n",
       "      <th>NUM_DEAL</th>\n",
       "      <th>LAST_DEAL</th>\n",
       "      <th>ADVANCE_PURCHASE</th>\n",
       "      <th>FARE_L_Y1</th>\n",
       "      <th>FARE_L_Y2</th>\n",
       "      <th>...</th>\n",
       "      <th>POINTS_L_Y2</th>\n",
       "      <th>POINTS_L_Y3</th>\n",
       "      <th>POINTS_L_Y4</th>\n",
       "      <th>POINTS_L_Y5</th>\n",
       "      <th>COUPON_FLAG</th>\n",
       "      <th>CANCEL_FLAG</th>\n",
       "      <th>CREDIT_FLAG</th>\n",
       "      <th>RELATED_FLAG</th>\n",
       "      <th>BUYER_FLAG</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9.493459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26.7</td>\n",
       "      <td>27</td>\n",
       "      <td>120.7</td>\n",
       "      <td>112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.5</td>\n",
       "      <td>104.6</td>\n",
       "      <td>110.9</td>\n",
       "      <td>137.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>12.200276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58.7</td>\n",
       "      <td>21</td>\n",
       "      <td>124.0</td>\n",
       "      <td>120.7</td>\n",
       "      <td>...</td>\n",
       "      <td>147.9</td>\n",
       "      <td>123.4</td>\n",
       "      <td>120.4</td>\n",
       "      <td>119.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>8.248704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28</td>\n",
       "      <td>143.3</td>\n",
       "      <td>145.3</td>\n",
       "      <td>...</td>\n",
       "      <td>167.3</td>\n",
       "      <td>163.3</td>\n",
       "      <td>169.4</td>\n",
       "      <td>152.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>13.308937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21.3</td>\n",
       "      <td>9</td>\n",
       "      <td>104.7</td>\n",
       "      <td>97.3</td>\n",
       "      <td>...</td>\n",
       "      <td>111.5</td>\n",
       "      <td>94.5</td>\n",
       "      <td>108.1</td>\n",
       "      <td>125.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>10.420929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.7</td>\n",
       "      <td>...</td>\n",
       "      <td>90.3</td>\n",
       "      <td>117.7</td>\n",
       "      <td>109.7</td>\n",
       "      <td>97.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29937</th>\n",
       "      <td>29938</td>\n",
       "      <td>8.813226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13.3</td>\n",
       "      <td>22</td>\n",
       "      <td>87.3</td>\n",
       "      <td>80.7</td>\n",
       "      <td>...</td>\n",
       "      <td>96.4</td>\n",
       "      <td>78.8</td>\n",
       "      <td>88.8</td>\n",
       "      <td>100.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29947</th>\n",
       "      <td>29948</td>\n",
       "      <td>12.060344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14</td>\n",
       "      <td>95.3</td>\n",
       "      <td>100.7</td>\n",
       "      <td>...</td>\n",
       "      <td>106.4</td>\n",
       "      <td>87.6</td>\n",
       "      <td>139.9</td>\n",
       "      <td>94.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29968</th>\n",
       "      <td>29969</td>\n",
       "      <td>9.308334</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>48.0</td>\n",
       "      <td>22</td>\n",
       "      <td>218.7</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>192.6</td>\n",
       "      <td>219.3</td>\n",
       "      <td>218.7</td>\n",
       "      <td>223.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29979</th>\n",
       "      <td>29980</td>\n",
       "      <td>12.411760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>45.3</td>\n",
       "      <td>14</td>\n",
       "      <td>146.0</td>\n",
       "      <td>141.3</td>\n",
       "      <td>...</td>\n",
       "      <td>188.8</td>\n",
       "      <td>144.1</td>\n",
       "      <td>155.6</td>\n",
       "      <td>154.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29983</th>\n",
       "      <td>29984</td>\n",
       "      <td>7.964462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>17</td>\n",
       "      <td>79.3</td>\n",
       "      <td>95.3</td>\n",
       "      <td>...</td>\n",
       "      <td>79.7</td>\n",
       "      <td>99.2</td>\n",
       "      <td>126.3</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1861 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  CUSTOMER_GRADE  STATUS_PANTINUM  STATUS_GOLD  STATUS_SILVER  \\\n",
       "1          2        9.493459                0            0              0   \n",
       "13        14       12.200276                0            0              0   \n",
       "17        18        8.248704                0            0              1   \n",
       "92        93       13.308937                0            0              0   \n",
       "94        95       10.420929                0            0              0   \n",
       "...      ...             ...              ...          ...            ...   \n",
       "29937  29938        8.813226                0            0              0   \n",
       "29947  29948       12.060344                0            0              0   \n",
       "29968  29969        9.308334                0            1              0   \n",
       "29979  29980       12.411760                0            0              1   \n",
       "29983  29984        7.964462                0            0              0   \n",
       "\n",
       "       NUM_DEAL  LAST_DEAL  ADVANCE_PURCHASE  FARE_L_Y1  FARE_L_Y2  ...  \\\n",
       "1             5       26.7                27      120.7      112.0  ...   \n",
       "13            2       58.7                21      124.0      120.7  ...   \n",
       "17            6       24.0                28      143.3      145.3  ...   \n",
       "92            5       21.3                 9      104.7       97.3  ...   \n",
       "94            6       16.0                15       90.0       90.7  ...   \n",
       "...         ...        ...               ...        ...        ...  ...   \n",
       "29937         7       13.3                22       87.3       80.7  ...   \n",
       "29947         5       16.0                14       95.3      100.7  ...   \n",
       "29968         5       48.0                22      218.7      224.0  ...   \n",
       "29979         3       45.3                14      146.0      141.3  ...   \n",
       "29983         3       34.7                17       79.3       95.3  ...   \n",
       "\n",
       "       POINTS_L_Y2  POINTS_L_Y3  POINTS_L_Y4  POINTS_L_Y5  COUPON_FLAG  \\\n",
       "1            112.5        104.6        110.9        137.3            0   \n",
       "13           147.9        123.4        120.4        119.5            0   \n",
       "17           167.3        163.3        169.4        152.3            0   \n",
       "92           111.5         94.5        108.1        125.2            0   \n",
       "94            90.3        117.7        109.7         97.2            0   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "29937         96.4         78.8         88.8        100.9            0   \n",
       "29947        106.4         87.6        139.9         94.5            0   \n",
       "29968        192.6        219.3        218.7        223.8            0   \n",
       "29979        188.8        144.1        155.6        154.2            0   \n",
       "29983         79.7         99.2        126.3        103.5            0   \n",
       "\n",
       "       CANCEL_FLAG  CREDIT_FLAG  RELATED_FLAG  BUYER_FLAG  Rating  \n",
       "1                0            1             0           0     0.0  \n",
       "13               0            0             0           1     1.0  \n",
       "17               0            0             0           0     0.0  \n",
       "92               0            0             0           0     1.0  \n",
       "94               0            0             0           0     0.0  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "29937            1            0             0           0     0.0  \n",
       "29947            0            0             0           0     0.0  \n",
       "29968            0            0             1           1     1.0  \n",
       "29979            0            0             0           1     1.0  \n",
       "29983            0            0             0           0     0.0  \n",
       "\n",
       "[1861 rows x 24 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model2_train_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [00:29<00:00, 16.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The Model is <class 'xgboost.sklearn.XGBClassifier'>.\n",
      "The number of features picked is 10.\n",
      "The depth selected is 2\n",
      "The treshold chosen is 0.027.\n",
      "The F1 score is 0.6382978723404256\n",
      ".~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6382978723404256,\n",
       " 'features': ['STATUS_PANTINUM',\n",
       "  'STATUS_GOLD',\n",
       "  'STATUS_SILVER',\n",
       "  'FARE_L_Y1',\n",
       "  'FARE_L_Y4',\n",
       "  'FARE_L_Y5',\n",
       "  'POINTS_L_Y4',\n",
       "  'POINTS_L_Y5',\n",
       "  'COUPON_FLAG',\n",
       "  'Rating'],\n",
       " 'model': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "               colsample_bylevel=None, colsample_bynode=None,\n",
       "               colsample_bytree=None, early_stopping_rounds=None,\n",
       "               enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "               gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "               interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "               max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "               max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               predictor=None, random_state=None, ...),\n",
       " 'depth': 2,\n",
       " 'treshold': 0.027}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {\"score\": 0}\n",
    "\n",
    "for i in tqdm(range(1, 500, 1)):\n",
    "    treshold = i / 1000\n",
    "    selected = select_features_by_corr(df_model2_train_both, treshold)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_xgboost(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "        best_params['treshold'] = treshold\n",
    "        best_params['features'] = selected\n",
    "        \n",
    "params_xgb_corr = best_params\n",
    "show_output(params_xgb_corr)\n",
    "params_xgb_corr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Random Forest with selection by corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:26<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The Model is <class 'xgboost.sklearn.XGBClassifier'>.\n",
      "The number of features picked is 10.\n",
      "The depth selected is 2\n",
      "The percentile value is 43.\n",
      "The F1 score is 0.6382978723404256\n",
      ".~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {\"score\": 0}\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)):\n",
    "    selected = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_xgboost(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "        best_params['percentile'] = p\n",
    "        best_params['features'] = selected\n",
    "\n",
    "params_xgb_per = best_params\n",
    "show_output(params_xgb_per)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now repeat the algorithmes above, using the select percentile function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 499/499 [41:09<00:00,  4.95s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "The Model is <class 'sklearn.ensemble._forest.RandomForestClassifier'>.\n",
      "The number of features picked is 5.\n",
      "The treshold chosen is 0.031.\n",
      "The F1 score is 0.6326530612244898\n",
      ".~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {\"score\": 0}\n",
    "\n",
    "for i in tqdm(range(1, 500, 1)):\n",
    "    treshold = i / 1000\n",
    "    selected = select_features_by_corr(df_model2_train_both, treshold)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_rf(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "        best_params['treshold'] = treshold\n",
    "        best_params['features'] = selected\n",
    "\n",
    "params_rf_corr = best_params\n",
    "show_output(params_rf_corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the RandomForest with the selectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [37:15<10:21, 32.73s/it] "
     ]
    }
   ],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {\"score\": 0}\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)):\n",
    "    selected = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_rf(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "        best_params['percentile'] = p\n",
    "        best_params['features'] = selected\n",
    "\n",
    "params_rf_per = best_params\n",
    "show_output(params_rf_per)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Table containing ffp data only\n",
    "\n",
    "Need to rerun models...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_ffp_train.drop([\"ID\", \"BUYER_FLAG\"], axis=1)\n",
    "label = df_ffp_train[\"BUYER_FLAG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {\"score\": 0}\n",
    "\n",
    "for i in tqdm(range(1, 500, 1)):\n",
    "    treshold = i / 1000\n",
    "    selected = select_features_by_corr(df_ffp_train,treshold)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_xgboost(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "        best_params['treshold'] = treshold\n",
    "        best_params['features'] = selected\n",
    "\n",
    "params_xgb_corr = best_params\n",
    "show_output(params_xgb_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {\"score\": 0}\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)):\n",
    "    selected = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_xgboost(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "        best_params['percentile'] = p\n",
    "        best_params['features'] = selected\n",
    "\n",
    "params_xgb_per = best_params\n",
    "show_output(params_xgb_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {\"score\": 0}\n",
    "\n",
    "for i in tqdm(range(1, 500, 1)):\n",
    "    treshold = i / 1000\n",
    "    selected = select_features_by_corr(df_ffp_train,treshold)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_rf(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "        best_params['treshold'] = treshold\n",
    "        best_params['features'] = selected\n",
    "\n",
    "params_rf_corr = best_params\n",
    "show_output(params_rf_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = -1\n",
    "params = {}\n",
    "best_params = {\"score\": 0}\n",
    "\n",
    "for p in tqdm(range(1, 101, 1)):\n",
    "    selected = select_features_by_SelecPer(features, label, p)\n",
    "\n",
    "    if prev == len(selected):\n",
    "        continue\n",
    "    prev = len(selected)\n",
    "\n",
    "    params = get_best_rf(features[selected], label)\n",
    "    if params['score'] > best_params['score']:\n",
    "        best_params = params\n",
    "        best_params['percentile'] = p\n",
    "        best_params['features'] = selected\n",
    "\n",
    "params_rf_per = best_params\n",
    "show_output(params_rf_per)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the \"Winning\" models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = ''\n",
    "model2 = ''\n",
    "\n",
    "recommandations = pd.DataFrame(columns=\"BUYER_FLAG\")\n",
    "\n",
    "def combined_model(row):\n",
    "    x = row.drop([\"BUYER_FLAG\"], axis=1)\n",
    "    if x[\"Rating\"].isna():\n",
    "        return model2.predict(x.drop([\"Rating\"], axis=1))\n",
    "    return model1.predict(x)\n",
    "\n",
    "recommandations[\"BUYER_FLAG\"] = pd.apply(data=merged_ffp_rollout, combined_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bcf8e034ec59c40d3e2b8291fca7d85d5ba7b622c5aa779388253272f8fcb6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
